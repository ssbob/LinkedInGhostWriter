{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f20bb1-c88d-4b94-b05f-82252f109137",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65bd69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Environment Variables\n",
    "import os\n",
    "\n",
    "# Loading of environment variables (API keys, etc.)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LinkedIn requirements\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98123655",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063daa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, model_name='gpt-4', client=\"my_client\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c2b68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_posts(screen_name, posts_to_return=12):\n",
    "    url = \"https://fresh-linkedin-profile-data.p.rapidapi.com/get-profile-posts\"\n",
    "\n",
    "    querystring = {\"linkedin_url\": f\"https://www.linkedin.com/in/{screen_name}/\", \"type\": \"posts\"}   # replace with your LinkedIn URL\n",
    "    \n",
    "    headers = {\n",
    "\t\"X-RapidAPI-Key\": \"abc123\", # replace with your API key\n",
    "\t\"X-RapidAPI-Host\": \"somehost.com\" # replace with your host\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    # load the data into a Python dictionary\n",
    "    data = json.loads(response.text)\n",
    "    print(response.text)\n",
    "\n",
    "    # access the 'data' field (a list of posts)\n",
    "    posts = data['data']\n",
    "\n",
    "    # sort posts by 'num_likes' in descending order\n",
    "    sorted_posts = sorted(posts, key=lambda post: post['num_likes'], reverse=True)\n",
    "\n",
    "    # get the 'text' field of the top 100 posts\n",
    "    texts = [post['text'] for post in sorted_posts[:posts_to_return]]   \n",
    "\n",
    "    # join the texts into a single string separated by two new lines\n",
    "    example_posts = '\\n\\n'.join(texts)\n",
    "    return example_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_screen_name = 'sean-fay-mba-8a598b9'  # Replace this with the desired user's screen name\n",
    "users_tweets = get_users_posts(user_screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad15d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d25d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Please create me a LinkedIn post about going to the park and eating a sandwich.\n",
    "\n",
    "% TONE\n",
    " - Don't use any emojis or hashtags.\n",
    " - Respond in the tone of Steve Chambers\n",
    "\n",
    "% START OF EXAMPLE POSTS TO MIMIC\n",
    "{example_posts}\n",
    "% END OF EXAMPLE POSTS TO MIMIC\n",
    "\n",
    "YOUR POST:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"example_posts\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(example_posts=example_posts)\n",
    "\n",
    "print (final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatOpenAI:\n",
    "    def predict(self, prompt):\n",
    "        # implementation of the predict method\n",
    "        return \"prediction\"\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee37ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Can you please generate a list of tone attributes and a description to describe a piece of writing by?\n",
    "\n",
    "Things like pace, mood, etc.\n",
    "\n",
    "Respond with nothing else besides the list\n",
    "\"\"\"\n",
    "\n",
    "how_to_describe_tone = llm.predict(prompt)\n",
    "print (how_to_describe_tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1a75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors_tone_description(how_to_describe_tone, sorted_posts):\n",
    "    template = \"\"\"\n",
    "        You are an AI Bot that is very good at generating writing in a similar tone as examples.\n",
    "        Be opinionated and have an active voice.\n",
    "        Take a strong stance with your response.\n",
    "\n",
    "        % HOW TO DESCRIBE TONE\n",
    "        {how_to_describe_tone}\n",
    "\n",
    "        % START OF EXAMPLES\n",
    "        {sorted_posts}\n",
    "        % END OF EXAMPLES\n",
    "\n",
    "        List out the tone qualities of the examples above\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"how_to_describe_tone\", \"sorted_posts\"],\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt.format(how_to_describe_tone=how_to_describe_tone, sorted_posts=sorted_posts)\n",
    "\n",
    "    authors_tone_description = llm.predict(final_prompt)\n",
    "\n",
    "    return authors_tone_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_tone_description = get_authors_tone_description(how_to_describe_tone, sorted_posts)\n",
    "print (authors_tone_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99dee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "% INSTRUCTIONS\n",
    " - You are an AI Bot that is very good at mimicking an author writing style.\n",
    " - Your goal is to write content with the tone that is described below.\n",
    " - Do not go outside the tone instructions below\n",
    " - Do not use hashtags or emojis\n",
    " - Respond in the tone of Steve Chambers\n",
    "\n",
    "% Description of the authors tone:\n",
    "{authors_tone_description}\n",
    "\n",
    "% Authors writing samples\n",
    "{sorted_posts}\n",
    "\n",
    "% YOUR TASK\n",
    "Please create a LinkedIn about going to the park and eating a sandwich.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"authors_tone_description\", \"sorted_posts\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(authors_tone_description=authors_tone_description, sorted_posts=sorted_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b48094",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict(final_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
